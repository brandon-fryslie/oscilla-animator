# Sprint Plan: Phase 6 Sprint 2 - FrameCache + Step Executors

**Generated:** 2025-12-26-092613
**Planner:** status-planner
**Source STATUS:** STATUS-2025-12-26-092613.md
**Sprint:** Phase 6 Sprint 2
**Focus:** Integrate SigEvaluator and FieldMaterializer into step executors with per-frame caching

---

## Executive Summary

Sprint 2 builds on Sprint 1's foundation (ValueStore + StateBuffer) by **integrating existing Phase 4-5 evaluators** (SigEvaluator, FieldMaterializer) into the scheduled runtime. This sprint implements per-frame memoization (FrameCache) and wires real evaluation logic into step executors.

**Deliverables:** 3 items (P0: FrameCache + BusEval, P1: Materialize)
**Estimated Complexity:** Medium (integration-focused, existing evaluators work)
**Test Target:** 60+ new tests
**Risk Level:** Low-Medium (cache ownership design decision required)

---

## Sprint 2 Scope

### In Scope
- ✓ FrameCache implementation with signal/field cache arrays
- ✓ executeBusEval integration with real combine logic
- ✓ executeMaterialize integration with FieldMaterializer
- ✓ Per-frame cache invalidation

### Out of Scope (Deferred)
- ✗ executeNodeEval (verify usage first, likely Sprint 3)
- ✗ executeRenderAssemble (Sprint 3)
- ✗ executeDebugProbe (Phase 7)
- ✗ Hot-swap semantics (Sprint 3)
- ✗ Cross-frame memoization (future optimization)

---

## Backlog by Priority

---

## P0 (Critical): FrameCache Implementation

**Status:** Not Started
**Effort:** Medium (150-200 lines impl + tests)
**Dependencies:** Sprint 1 complete
**Spec Reference:** design-docs/12-Compiler-Final/17-Scheduler-Full.md §1.2 (lines 64-98), §8 • STATUS-2025-12-26-092613.md §"What's Missing for Sprint 2" → "1. FrameCache System"

### Description

Implement per-frame memoization cache for signal values, field handles, and materialized buffers. This is the central cache used by all evaluators to avoid redundant computation within a single frame.

Currently, RuntimeState has a stub FrameCache with only frameId tracking. SigEvaluator and FieldMaterializer each maintain their own separate cache structures. Sprint 2 unifies these under a canonical FrameCache in RuntimeState.

**Key Design Decision:** FrameCache must match the interface expected by SigEvaluator (sigValue/sigStamp arrays) and FieldMaterializer (field handle cache + buffer pool).

### Acceptance Criteria

- [ ] FrameCache interface expanded with cache storage fields:
  - [ ] `sigValue: Float64Array` - Cached signal values
  - [ ] `sigStamp: Uint32Array` - Frame stamps for signal cache validation
  - [ ] `fieldHandle: FieldHandle[]` - Cached field handles (lazy recipes)
  - [ ] `fieldStamp: Uint32Array` - Frame stamps for field cache validation
  - [ ] `fieldBuffers: Map<string, ArrayBufferView>` - Materialized buffer pool
- [ ] `createFrameCache(capacity)` factory function allocates cache arrays
  - [ ] Allocates Float64Array and Uint32Array for signals (size = capacity)
  - [ ] Allocates FieldHandle[] and Uint32Array for fields (size = capacity)
  - [ ] Initializes empty Map for buffer pool
- [ ] `newFrame()` method invalidates per-frame caches correctly
  - [ ] Increments frameId
  - [ ] Does NOT zero arrays (stamps invalidate stale entries)
  - [ ] Clears fieldBuffers Map (new frame = new materializations)
- [ ] `invalidate()` method clears all caches (for hot-swap)
  - [ ] Zeros all stamp arrays (forces recomputation)
  - [ ] Clears fieldBuffers Map
- [ ] Unit tests (25-30 tests):
  - [ ] Signal cache hit/miss based on stamp matching
  - [ ] Field cache hit/miss based on stamp matching
  - [ ] newFrame() invalidates stamps correctly
  - [ ] Buffer pool cleared on newFrame()
  - [ ] invalidate() clears everything
  - [ ] Multiple calls to newFrame() increment frameId monotonically
  - [ ] Cache capacity handling (what happens if id >= capacity?)

### Technical Notes

**Cache Capacity:**
- SigEvaluator capacity = max SigExprId in program
- FieldMaterializer capacity = max FieldExprId in program
- RuntimeState should allocate based on program's SignalExprTable.count and FieldExprTable.count

**Stamp-Based Invalidation:**
- Stamps are Uint32Array where stamp[id] === frameId means "cached for this frame"
- newFrame() increments frameId, making all stamps < frameId invalid
- No need to zero value arrays - stamp check is authoritative

**Buffer Pool Key:**
- Key format: `${fieldId}_${domainId}_${format}` (or similar)
- Used by FieldMaterializer to avoid re-materializing same buffer in one frame

**Integration Path:**
- Phase 1: Implement FrameCache in RuntimeState.ts
- Phase 2: Update SigEvaluator to accept FrameCache in SigEnv
- Phase 3: Update FieldMaterializer to accept FrameCache in FieldEnv

---

## P0 (Critical): executeBusEval Integration

**Status:** Not Started
**Effort:** Medium (100-150 lines impl + tests)
**Dependencies:** P0 FrameCache implementation
**Spec Reference:** design-docs/12-Compiler-Final/17-Scheduler-Full.md §7 (lines 383-407) • STATUS-2025-12-26-092613.md §"What's Missing for Sprint 2" → "2. executeBusEval Integration"

### Description

Implement real bus combine logic in executeBusEval step executor. Currently, the stub returns silent value (0) or the first publisher's value. Sprint 2 implements all combine modes (sum, average, min, max, last) and applies transform chains to publisher values before combining.

**Key Challenge:** StepBusEval IR operates on slots (low-level), while SigEvaluator.evalBusCombine operates on SignalExpr nodes (high-level). May need to implement combine logic directly in executeBusEval rather than delegating to SigEvaluator.

### Acceptance Criteria

- [ ] Read publisher source values from ValueStore (one value per publisher)
- [ ] Filter enabled publishers (respect `enabled: boolean` flag)
- [ ] Apply transform chains to each publisher value BEFORE combining
  - [ ] Support all transform step kinds (adapter, lens)
  - [ ] Use existing transform chain evaluation from SigEvaluator or implement inline
- [ ] Implement all combine modes for signal buses:
  - [ ] `sum` - Add all publisher values
  - [ ] `average` - Mean of all publisher values
  - [ ] `min` - Minimum publisher value
  - [ ] `max` - Maximum publisher value
  - [ ] `last` - Last publisher value (deterministic order from sortKey)
- [ ] Handle silent value policy when no publishers enabled:
  - [ ] `silent.kind === "zero"` → write 0
  - [ ] `silent.kind === "default"` → write type-specific default (0 for numbers)
  - [ ] `silent.kind === "const"` → read from const pool
- [ ] Write combined value to `step.outSlot` in ValueStore
- [ ] Unit tests (20-25 tests):
  - [ ] Each combine mode with 2-3 publishers
  - [ ] Silent value handling (zero, default, const)
  - [ ] Transform chain application (scale, bias, ease, etc.)
  - [ ] Publisher ordering (sortKey determinism)
  - [ ] Empty publisher list (should use silent value)
  - [ ] All publishers disabled (should use silent value)
  - [ ] Single publisher (combine mode should still apply correctly)

### Technical Notes

**Publisher Ordering:**
- Publishers in `step.publishers` are already sorted by compiler (sortKey, then publisherId)
- executeBusEval must preserve this order for determinism

**Transform Chains:**
- Option 1: Call SigEvaluator.evalTransform() for each publisher value
- Option 2: Implement transform logic inline in executeBusEval
- Recommendation: Option 1 (reuse existing code) if feasible

**Silent Value:**
- `step.silent.constId` references const pool (program.constants.f64, etc.)
- Need access to ConstPool in executor context

**Field Buses:**
- Field bus combine is different - combines FieldHandle recipes, not materialized arrays
- Field bus combine may be handled in executeMaterialize or a separate step
- For Sprint 2, focus on SIGNAL buses only (numeric values)

---

## P1 (High): executeMaterialize Integration

**Status:** Not Started
**Effort:** Medium (80-120 lines impl + tests)
**Dependencies:** P0 FrameCache implementation
**Spec Reference:** design-docs/12-Compiler-Final/17-Scheduler-Full.md §5.3 (lines 295-347) • STATUS-2025-12-26-092613.md §"What's Missing for Sprint 2" → "3. executeMaterialize Integration"

### Description

Integrate FieldMaterializer into executeMaterialize step executor. Currently, the stub returns an empty Float32Array. Sprint 2 constructs a MaterializationRequest from StepMaterialize IR, calls FieldMaterializer.materialize(), and writes the resulting buffer to ValueStore.

**Key Integration:** FieldMaterializer expects MaterializationRequest with fieldId, domainId, format, layout, usageTag. StepMaterialize IR should have all this information.

### Acceptance Criteria

- [ ] Read domain count from ValueStore using `step.materialization.domainSlot`
  - [ ] Domain count is a numeric value (integer N)
  - [ ] Represents number of elements in field buffer
- [ ] Construct MaterializationRequest from StepMaterialize:
  - [ ] `fieldId: FieldId` from step.materialization.fieldId
  - [ ] `domainId: number` from step.materialization.domainId (or derived)
  - [ ] `format: BufferFormat` from step.materialization.format
  - [ ] `layout: BufferLayout` from step.materialization.layout (if present)
  - [ ] `usageTag: string` from step.materialization.usageTag (e.g. "pos", "radius", "color")
- [ ] Construct FieldEnv with:
  - [ ] Signal environment (time, const pool, SigEvaluator access)
  - [ ] Field cache from FrameCache (fieldHandle, fieldStamp)
  - [ ] Buffer pool from FrameCache.fieldBuffers
- [ ] Call FieldMaterializer.materialize(request, env) to get typed array
- [ ] Write buffer handle to `step.materialization.outBufferSlot` in ValueStore
  - [ ] Buffer handle is an object: `{ kind: "buffer", data: TypedArray, format: BufferFormat }`
  - [ ] ValueStore.write() supports object storage for buffer slots
- [ ] Respect per-frame buffer pool cache:
  - [ ] Same (fieldId, domainId, format) within frame → return cached buffer
  - [ ] Different frames → re-materialize
- [ ] Unit tests (15-20 tests):
  - [ ] Basic materialization (const field → buffer of N identical values)
  - [ ] Broadcast field (signal value → buffer of N copies)
  - [ ] Zip field (two fields combined element-wise)
  - [ ] Buffer pool reuse (same field requested twice in frame → same buffer instance)
  - [ ] Different frames (newFrame() → re-materialize)
  - [ ] Domain count from slot (various N values)
  - [ ] Format/layout handling (f32, f64, vec2f32, etc.)

### Technical Notes

**Domain Count Resolution:**
- Domain count is written to a ValueStore slot by previous steps
- executeMaterialize reads this slot to get N
- If domainSlot is missing or zero, throw error (cannot allocate buffer)

**MaterializationRequest Construction:**
- StepMaterialize.materialization should have all required fields
- If missing fields (e.g. layout), use sensible defaults (AoS layout for vec types)

**Buffer Handle Storage:**
- ValueStore supports object storage for buffer slots
- Object slots use `storage: "object"` in SlotMeta
- Buffer handle shape: `{ kind: "buffer", data: TypedArray, format: BufferFormat }`

**FieldMaterializer Context:**
- FieldMaterializer needs SigEnv to evaluate broadcast nodes (signal→field)
- SigEnv should point to same FrameCache signal cache
- Need to pass RuntimeState or construct envs from RuntimeState

**Fusion (Future Optimization):**
- FieldMaterializer supports fusion (combine ops without intermediate buffers)
- Sprint 2 focuses on correctness, not optimization
- Fusion is internal to FieldMaterializer - no changes needed in executeMaterialize

---

## Dependency Graph

```
P0: FrameCache Implementation
  └─> P0: executeBusEval Integration
  └─> P1: executeMaterialize Integration

(No cross-dependencies between BusEval and Materialize)
```

**Critical Path:** FrameCache → BusEval/Materialize (parallel)

---

## Recommended Sprint Execution Order

### Phase 1: FrameCache Foundation (Day 1)
1. Expand FrameCache interface in RuntimeState.ts
2. Implement createFrameCache(capacity) factory
3. Implement newFrame() and invalidate() methods
4. Write 25-30 unit tests for cache behavior
5. Verify: All tests pass, FrameCache works standalone

### Phase 2: executeBusEval Integration (Day 2)
1. Implement combine modes (sum, average, min, max, last) in executeBusEval.ts
2. Implement silent value handling
3. Add transform chain application (or delegate to SigEvaluator)
4. Write 20-25 unit tests for combine logic
5. Verify: All tests pass, bus combine matches spec

### Phase 3: executeMaterialize Integration (Day 2-3)
1. Construct MaterializationRequest from StepMaterialize
2. Wire FieldMaterializer.materialize() into executeMaterialize.ts
3. Handle domain count resolution and buffer handle storage
4. Write 15-20 unit tests for materialization
5. Verify: All tests pass, field materialization works

### Phase 4: Integration Verification (Day 3)
1. Run full test suite (1724 existing + 60 new = 1784 total)
2. Verify no regressions in Sprint 1 tests
3. Verify SigEvaluator and FieldMaterializer still pass their tests
4. Update STATUS file with completion notes

---

## Risk Assessment

### High-Risk Items
None - all work is integration of existing, tested components.

### Medium-Risk Items

1. **Cache Ownership Design**
   - **Risk:** FrameCache interface may not match SigEvaluator/FieldMaterializer expectations
   - **Mitigation:** Review SigEnv and FieldEnv interfaces first, design FrameCache to match
   - **Contingency:** Adapt evaluators to new FrameCache structure (small changes)

2. **BusEval Abstraction Mismatch**
   - **Risk:** StepBusEval IR may not have enough info to call SigEvaluator.evalBusCombine()
   - **Mitigation:** Implement combine logic directly in executeBusEval if needed
   - **Contingency:** Duplicate combine logic (not ideal but functional)

### Low-Risk Items

1. **Domain Count Resolution**
   - **Risk:** Unclear where domain count comes from
   - **Mitigation:** Read from domainSlot in ValueStore (spec says it's a slot)

2. **Buffer Pool Key Format**
   - **Risk:** Key collisions or format mismatches
   - **Mitigation:** Use same key format as FieldMaterializer (check existing code)

---

## Success Metrics

### Quantitative
- ✓ 60+ new tests added (FrameCache: 25-30, BusEval: 20-25, Materialize: 15-20)
- ✓ All 1784 tests pass (1724 existing + 60 new)
- ✓ Zero test regressions
- ✓ Step executor coverage: 50% (3/6 functional: timeDerive, BusEval, Materialize)

### Qualitative
- ✓ FrameCache is canonical - used by SigEvaluator and FieldMaterializer
- ✓ executeBusEval implements all combine modes correctly
- ✓ executeMaterialize produces correct typed arrays
- ✓ Per-frame cache invalidation works (newFrame() clears stamps)
- ✓ No stubs in production code for implemented features
- ✓ No `any` types in new code (type-safe throughout)

---

## Out of Scope (Explicitly Deferred)

### Sprint 3 Work
- executeNodeEval implementation (verify if actually used first)
- executeRenderAssemble + render tree assembly
- Hot-swap state preservation semantics
- Legacy runtime removal preparation

### Phase 7 Work
- executeDebugProbe implementation
- Trace emission in step executors
- Debug span ring buffers

### Future Optimizations
- Cross-frame memoization (untilInvalidated cache mode)
- Field materialization fusion optimizations
- SIMD/WASM acceleration
- Typed array pooling beyond per-frame

---

## Acceptance Criteria Summary

**Sprint 2 is COMPLETE when:**

1. ✓ FrameCache interface includes signal/field cache arrays
2. ✓ createFrameCache() allocates real cache storage
3. ✓ newFrame() and invalidate() methods work correctly
4. ✓ executeBusEval implements all combine modes (sum, avg, min, max, last)
5. ✓ executeBusEval handles silent values correctly
6. ✓ executeMaterialize integrates FieldMaterializer
7. ✓ executeMaterialize writes buffer handles to ValueStore
8. ✓ 60+ new tests added, all passing
9. ✓ All 1724 existing tests still pass (no regressions)
10. ✓ No TODOs in production code for delivered features
11. ✓ Type-safe throughout (no `any` types)

---

## Next Sprint Preview (Sprint 3)

**Focus:** Render assembly + hot-swap
**Deliverables:**
- executeRenderAssemble implementation
- Hot-swap state preservation (layout-hash matching)
- Verify executeNodeEval usage (implement if needed, remove if not)
- Legacy runtime removal preparation

**Target:** Complete Phase 6 scheduled runtime, ready for Phase 7 debug infrastructure.
