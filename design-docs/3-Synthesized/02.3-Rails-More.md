Yes — and this is the moment where the design either becomes modular or collapses back into a brittle special-case.

Let me be very clear about the architecture.

What you have right now:

“Rails are driven by the Time Console (cycles) and optionally mirrored into buses.”

That is only half of a modular system.

A true modular system must also allow the inverse:

Rails can be driven by the graph.

Otherwise:
	•	Phase A and Phase B are not oscillators
	•	They are just hardcoded metronomes
	•	And you’ve re-invented a timeline with two knobs

That would absolutely cap the system’s expressive ceiling.

⸻

The real abstraction

The correct abstraction is:

A Rail is a named, patch-global signal endpoint with a drive policy.

It is not:
	•	a clock
	•	a cycle
	•	a bus
	•	or a block

It is a binding point.

Just like in modular synths:
	•	CV in
	•	CV out
	•	normalled when nothing is patched
	•	overridden when something is patched

You already invented this when you created Normalled / Patched / Mixed.
You just hadn’t finished the thought yet.

⸻

How modular synths actually do this

On a real Eurorack module:

There is a jack called LFO 1.

Internally:
	•	It is driven by an oscillator.

But when you plug a cable into it:
	•	The internal oscillator is disconnected.
	•	Whatever voltage comes from the cable becomes the LFO.

That is exactly what Rails must be.

⸻

What this means for Oscilla

Each Rail (phaseA, phaseB, energy, palette…) has:
	•	A default internal generator (from the Time Console)
	•	A patchable external input (from buses)
	•	A combine rule if both are active

The drive policy defines which one wins.

So yes:

The Time Console must expose a way to bind each Rail to a Bus.

This is not optional.

⸻

The three drive modes, concretely

For every Rail:

Mode	Meaning
Normalled	Use the internal generator from the Time Console
Patched	Ignore internal generator, take value from a Bus
Mixed	Combine internal + bus using rail’s combine rule

This is identical to:
	•	Normalled jack
	•	Patched jack
	•	Summed CV

⸻

What breaks if you don’t allow this

If Rails cannot be driven by buses, then:
	•	You cannot:
	•	sync a cycle to an event
	•	reset a phase
	•	slave a clock
	•	quantize rhythm
	•	side-chain motion
	•	or do generative timing

You end up with:
	•	Two nice oscillators
	•	That are forever isolated from the rest of the patch

That is not modular.
That is decorative.

⸻

The correct UI

In the Time Console, for each Rail row:

You must have:
	•	Source selector:
	•	Internal
	•	Bus
	•	Both
	•	If Bus or Both:
	•	A bus picker

Example:

Phase A:
  [ Internal ⬤ ] [ Bus ○ ] [ Both ○ ]
  Bus:  (none)

Pulse A:
  [ Internal ○ ] [ Bus ⬤ ] [ Both ○ ]
  Bus:  KickTriggers

That is the exact UI pattern of modular synths.

⸻

This makes the whole system click

Now:
	•	You can use Phase A internally for:
	•	basic motion
	•	Or override it with:
	•	a sequencer
	•	a beat detector
	•	a MIDI clock
	•	another phase generator

And the rest of the patch doesn’t know or care.

That is the whole point of Rails.

⸻

Question: But how do I actually implement this?  Doesn't the graph need to be acyclic?

----

So yes, your instinct was correct:

“I’m not sure the system will work if we don’t allow cycles like that.”

It won’t.

But once you allow Rails to be driven by buses,
it becomes a real modulation system instead of a dressed-up timeline.

You’re right to worry. If you naïvely “wire bus → rail → bus” you can create real cycles.

The trick is: a Rail is not a node in the user graph. It’s an externally scheduled endpoint with explicit rules about where it may be read/written, and (if you allow feedback) the feedback must cross a state boundary.

Here’s the clean, long-term implementation spec.

⸻

1) Model Rails as “named runtime registers”, not graph nodes

In the compiler’s dependency graph, do not create RailValue nodes that participate in topo sort the same way blocks do.

Instead, treat Rails as:
	•	Inputs to user blocks (read-only)
	•	Optional outputs of the Time Console overlay (write-only, scheduled first)
	•	Optional outputs of the user graph (write-only, scheduled after overlay)

At runtime, Rails live in a dedicated store:

type RailId = 'phaseA'|'phaseB'|'pulseA'|'pulseB'|'energy'|'palette'|...;

interface RailStore {
  signal: Record<RailId, SignalExprId>; // or handles into value store
  meta: Record<RailId, { driveMode: 'internal'|'bus'|'both'; combine: CombineMode; ... }>;
}

Think “register file”.

⸻

2) Define a strict evaluation schedule with phases

Your runtime already wants a scheduled model (good). Use it.

Schedule phases per frame

Phase 0 — TimeRoot
	•	Produce time (monotonic).

Phase 1 — Time Console overlay
	•	Compute internal rail candidates: railInternal[railId].

Phase 2 — User graph
	•	Evaluate user blocks in topo order with rail reads allowed.
	•	Compute user rail publishers: railUser[railId] (if any).

Phase 3 — Resolve rails
	•	For each rail:
	•	apply drive policy (normalled/patched/mixed)
	•	produce final railFinal[railId]
	•	Publish railFinal to bus fabric only if “mirroring” is enabled (your current spec).

Phase 4 — Render sinks
	•	RenderInstances2D materializes fields, produces RenderTree.

This gives you determinism and makes “rails” feel like a global control voltage plane.

⸻

3) Where the acyclic constraint actually applies

Acyclic applies to:
	•	User block → user block connections
	•	User publishers/listeners between blocks and buses
	•	Anything that the compiler schedules via topo sort

Acyclic does not need to apply to:
	•	Reading a rail (it’s just reading the current frame’s resolved value)
	•	Writing to a rail (it’s writing a staged value that is resolved later)

Because rails are resolved by the schedule, not by graph edges.

⸻

4) Preventing illegal feedback loops

Even with staged rails, you can still create semantic feedback like:
	•	energy drives something that publishes back into energy

That is a feedback loop across frames if you allow it, and it must be explicit.

Rule: Rail writes cannot depend on the same-frame final rail value

Concretely:
	•	In Phase 2, user blocks may read railFinal from previous frame (or “current frame pre-resolve” — pick one, but be explicit).
	•	In Phase 3, railFinal for this frame is computed.

This creates a deliberate 1-frame delay boundary, which is equivalent to a memory block.

This is exactly how modular synth feedback works in practice: the cable loop exists, but the system has finite propagation and state.

Choose one of these two semantics (pick and lock it):

Option A (recommended): Rails are “frame-latched”.
	•	Reads in Phase 2 see railFinal[t-1].
	•	Writes affect railFinal[t].
	•	This guarantees no instantaneous algebraic loops, ever.

Option B: Rails are “same-frame” but require memory boundary detection.
	•	Reads see railFinal[t].
	•	Then you must SCC-detect cycles that go through rails and require a state block.
	•	This is harder and will bite you.

If you care about performance + determinism + debuggability: Option A.

⸻

5) How “Rail driven by Bus” works without cycles

When a rail is in Patched or Mixed mode with a selected bus source:
	•	You are not actually wiring “bus graph → rail graph”.
	•	You are selecting a bus value handle to sample during the rail resolve step.

Implementation:
	•	During compilation, precompute for each rail:
	•	sourceBusId?: BusId
	•	sourceAdapterChain?: AdapterStep[] (optional)
	•	driveMode

At runtime Phase 3:

const busValue = evalBus(sourceBusId)           // bus evaluation is already well-defined
const adapted = applyAdapters(busValue, chain)
railUserCandidate = adapted
railFinal = resolve(railInternalCandidate, railUserCandidate, driveMode, combineMode)

Key point: rail resolve happens after user graph evaluation, so bus evaluation is already complete for the frame.

And with frame-latched reads, even if bus evaluation uses rails, it’s using the previous frame’s rails, so you stay acyclic.

⸻

6) Compiler changes (minimal but “right”)

You add a new compilation product:

interface CompiledTimeOverlay {
  internal: Record<RailId, SignalExprId>; // generated from Time Console (cycles, palette gen, etc.)
  policy: Record<RailId, RailPolicy>;     // normalled/patched/mixed + combine rules
  busBindings: Record<RailId, null | { busId: string; adapters?: AdapterStep[] }>;
}

And the compiled program becomes:

interface CompiledProgram {
  schedule: {
    timeRoot: Step[];
    overlay: Step[];
    userGraph: Step[];      // topo-ordered block steps
    railResolve: Step[];    // deterministic per-rail
    render: Step[];
  };
  valueStoreLayout: ...;    // indexed handles for speed + Rust path
}

No rails appear as nodes in the topo graph.

⸻

7) Diagnostics you absolutely need

When a user picks “Bus” as a rail source:
	•	If the selected bus ultimately depends on that same rail in a way that creates same-frame dependency, that’s fine under frame-latched semantics but you must surface it as:

“This creates a feedback loop via rail energy. Oscilla will apply a 1-frame delay automatically (rail is frame-latched).”

And show in power-user debug:
	•	rail read = previous frame
	•	rail write = current frame

So nobody goes insane.

⸻

Bottom line

You keep the user graph acyclic by:
	1.	Taking rails out of the dependency graph
	2.	Resolving rails in a dedicated schedule phase
	3.	Making rail reads frame-latched (effectively a built-in memory boundary)

That gives you:
	•	no algebraic loops
	•	deterministic behavior
	•	clean debug story
	•	easy Rust/WASM implementation (it’s just a register file + schedule)

If you want, next I can write the exact TypeScript types for RailPolicy, CompiledTimeOverlay, and the runtime RailStore/resolve algorithm so engineers can implement it without inventing anything.